
import os
import uuid
from flask import Flask, request
from dotenv import load_dotenv
from collections import defaultdict, deque

# LINE
from linebot.v3.messaging import MessagingApi, Configuration, ApiClient, ReplyMessageRequest, TextMessage
from linebot.v3.webhook import WebhookParser
from linebot.v3.webhooks import MessageEvent, TextMessageContent

# OpenAI & Pinecone
from openai import OpenAI
from pinecone import Pinecone

# Supabase
from supabase import create_client, Client

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# åˆå§‹åŒ–
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()

openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
index = pc.Index(os.getenv("PINECONE_INDEX"))

configuration = Configuration(access_token=os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
parser = WebhookParser(os.getenv("LINE_CHANNEL_SECRET"))

# Supabase client
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
SUPABASE_TABLE = os.getenv("SUPABASE_TABLE", "cars")   # é è¨­ cars
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

app = Flask(__name__)

# è¨˜æ†¶å°è©± & äººå·¥å®¢æœæ¨¡å¼
user_memory = defaultdict(lambda: deque(maxlen=10))
manual_mode = set()  # å­˜æ”¾é€²å…¥äººå·¥å®¢æœæ¨¡å¼çš„ user_id

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# å…±ç”¨å°å·¥å…·
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def embed_text(text: str) -> list:
    embedding = openai_client.embeddings.create(
        model="text-embedding-3-small",
        input=[text]
    )
    return embedding.data[0].embedding


def search_supabase(query: str, limit: int = 5) -> list:
    filter_cols = [
        "å» ç‰Œ", "è»Šæ¬¾", "è»Šå‹", "å¹´å¼", "å¹´ä»½", "é¡è‰²",
        "è»Šè¼›è³£é»", "è»Šè¼›å‰¯æ¨™é¡Œ", "å®‰å…¨æ€§é…å‚™", "èˆ’é©æ€§é…å‚™"
    ]
    or_filters = ",".join([f"{col}.ilike.*{query}*" for col in filter_cols])
    response = (
        supabase
        .table(SUPABASE_TABLE)
        .select("*")
        .or_(or_filters)
        .limit(limit)
        .execute()
    )
    return response.data or []


def format_car_record(rec: dict) -> str:
    return (
        f"{rec.get('å» ç‰Œ', '')} {rec.get('è»Šæ¬¾', '')} {rec.get('è»Šå‹', '')} "
        f"{rec.get('å¹´å¼', '')} â€” {rec.get('å¹´ä»½', '')}å¹´å¼ï¼Œ"
        f"é¡è‰²ï¼š{rec.get('é¡è‰²', 'æœªæ¨™ç¤º')}ï¼Œ"
        f"é‡Œç¨‹ï¼š{rec.get('è¡Œé§›é‡Œç¨‹', 'æœªæ¨™ç¤º')}ï¼Œ"
        f"å”®åƒ¹ï¼š{rec.get('è»Šè¼›å”®åƒ¹', 'æ´½è©¢')}ï¼Œ"
        f"è¯çµ¡äººï¼š{rec.get('è¯çµ¡äºº', 'N/A')}ï¼ˆ{rec.get('è¡Œå‹•é›»è©±', 'é›»è©±ä¸å…¬é–‹')}ï¼‰"
    ).strip()


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# LINE Webhook
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@app.route("/callback", methods=["POST"])
def callback():
    signature = request.headers.get("x-line-signature")
    body = request.get_data(as_text=True)

    try:
        events = parser.parse(body, signature)
    except Exception as e:
        print("[WebhookParser] Error:", e)
        return "Invalid signature", 400

    with ApiClient(configuration) as api_client:
        line_bot_api = MessagingApi(api_client)

        for event in events:
            if isinstance(event, MessageEvent) and isinstance(event.message, TextMessageContent):
                user_id = event.source.user_id
                query = event.message.text.strip()

                user_memory[user_id].append({"role": "user", "content": query})

                # åˆ‡æ›äººå·¥å®¢æœæ¨¡å¼
                if query == "äººå·¥å®¢æœæ‚¨å¥½":
                    manual_mode.add(user_id)
                    print(f"[äººå·¥æ¨¡å¼ ON] {user_id}")
                    return "OK", 200

                if query == "äººå·¥å®¢æœçµæŸ":
                    manual_mode.discard(user_id)
                    print(f"[äººå·¥æ¨¡å¼ OFF] {user_id}")
                    return "OK", 200

                if user_id in manual_mode:
                    print(f"[éœé»˜] {user_id} äººå·¥å®¢æœä¸­ï¼Œè·³é GPT å›è¦†")
                    return "OK", 200

                # 1) Pinecone æœå°‹
                vector = embed_text(query)
                res = index.query(vector=vector, top_k=5, include_metadata=True)
                matches = [m for m in res["matches"] if m["score"] >= 0.2]

                context = ""
                data_source = "pinecone"

                if matches:
                    context = "\n".join([m["metadata"]["text"] for m in matches])
                else:
                    # 2) Supabase fallback
                    records = search_supabase(query, limit=5)
                    if records:
                        context_lines = [format_car_record(r) for r in records]
                        context = "\n".join(context_lines)
                        data_source = "supabase"
                    else:
                        fallback = "äºéˆºæ™ºèƒ½å®¢æœæ‚¨å¥½ï¼šæ„Ÿè¬æ‚¨çš„è©¢å•ï¼Œç›®å‰æ‚¨çš„å•é¡Œéœ€è¦å°ˆäººå›è¦†æ‚¨ï¼Œè«‹ç¨å¾Œé¦¬ä¸Šæœ‰äººç‚ºæ‚¨æœå‹™ï¼ğŸ˜„"
                        user_memory[user_id].append({"role": "assistant", "content": fallback})
                        line_bot_api.reply_message(ReplyMessageRequest(
                            reply_token=event.reply_token,
                            messages=[TextMessage(text=fallback)]
                        ))
                        return "OK", 200

                memory_messages = list(user_memory[user_id])
                memory_messages.append({"role": "user", "content": query})

                system_prompt = {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯äºéˆºæ±½è»Šçš„50å¹´è³‡æ·±å®¢æœå°ˆå“¡ï¼Œæ“…é•·æ‹†è§£ä¸¦è§£ç­”å•é¡Œã€‚\n"
                        "è«‹å…ˆé–±è®€åƒè€ƒè³‡æ–™ï¼ˆè‹¥æœ‰ï¼‰å†å›ç­”ï¼›è‹¥å…§å®¹ä¸è¶³ï¼Œè«‹å…ˆæå‡ºéœ€è¦é€²ä¸€æ­¥è³‡è¨Šçš„å•é¡Œã€‚\n"
                        "è‹¥è©¢å•èˆ‡äºéˆºæ±½è»Šç„¡é—œï¼Œè«‹å›è¦†ï¼šæ„Ÿè¬æ‚¨çš„è©¢å•ï¼Œè«‹è©¢å•äºéˆºæ±½è»Šç›¸é—œå•é¡Œï¼Œæˆ‘å€‘å¾ˆé«˜èˆˆç‚ºæ‚¨æœå‹™ï¼ğŸ˜„"
                    )
                }
                user_prompt = {
                    "role": "user",
                    "content": f"ã€è³‡æ–™ä¾†æºï¼š{data_source}ã€‘\nåƒè€ƒè³‡æ–™ï¼š\n{context}\n\nå•é¡Œï¼š{query}"
                }

                chat_completion = openai_client.chat.completions.create(
                    model="gpt-4o",
                    messages=[system_prompt] + memory_messages + [user_prompt]
                )
                answer = chat_completion.choices[0].message.content.strip()
                if not answer.startswith("äºéˆºæ™ºèƒ½å®¢æœæ‚¨å¥½ï¼š"):
                    answer = "äºéˆºæ™ºèƒ½å®¢æœæ‚¨å¥½ï¼š" + answer

                user_memory[user_id].append({"role": "assistant", "content": answer})
                line_bot_api.reply_message(ReplyMessageRequest(
                    reply_token=event.reply_token,
                    messages=[TextMessage(text=answer)]
                ))

    return "OK", 200


@app.route("/")
def home():
    return "LINE GPT Bot Ready"


@app.route("/upload", methods=["POST"])
def upload_text():
    data = request.get_json()
    text = data.get("text", "").strip()
    if not text:
        return {"error": "Missing text"}, 400

    embedding = embed_text(text)
    doc_id = "web-" + str(uuid.uuid4())[:8]

    index.upsert([
        {"id": doc_id, "values": embedding, "metadata": {"text": text}}
    ])
    return {"message": "âœ… ä¸Šå‚³æˆåŠŸ", "id": doc_id}


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000)
